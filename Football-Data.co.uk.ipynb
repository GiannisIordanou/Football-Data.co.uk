{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Football-Data.co.uk Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "(\"global name 'np' is not defined\", u'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-53734a370296>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;31m# Add custom columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"HTSC\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_htsc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Fix HTSC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"FTSC\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_ftsc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Fix FTSC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Date\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mget_date\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Fix Date\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   3687\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3688\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3689\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3690\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3691\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Python27\\lib\\site-packages\\pandas\\core\\frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   3777\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3778\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3779\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3780\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3781\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-53734a370296>\u001b[0m in \u001b[0;36mget_htsc\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m     \u001b[0mhthg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"HTHG\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"HTAG\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhthg\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m         \u001b[1;31m#if hthg.dtype == float and htag.dtype == float:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[0mhtsc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhthg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhtag\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".0\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: (\"global name 'np' is not defined\", u'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "\n",
    "#Imports\n",
    "\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import workerpool\n",
    "import pandas as pd\n",
    "\n",
    "#Functions\n",
    " \n",
    "def get_country_urls(site):\n",
    "    \"\"\"\n",
    "    Get country urls from site.\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    site: string\n",
    "          Site url\n",
    "           \n",
    "    Returns\n",
    "    -------\n",
    "    countries: list\n",
    "               1-D list of strings,\n",
    "               name of countries\n",
    "     \n",
    "    countries_dict: dictionary\n",
    "                    1-D dictionary containing\n",
    "                    countries name and urls    \n",
    "    \"\"\"\n",
    "    try:\n",
    "        headers = {\"User-agent\": \"Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.9.0.1) \\\n",
    "                    Gecko/2008071615 Fedora/3.0.1-1.fc9 Firefox/3.0.1\"}\n",
    "        r = requests.get(site, headers=headers)\n",
    "        html = r.text       \n",
    "        pattern = '<A HREF=\"(http://www.football-data.co.uk/.*?m.php)\"><b>(.*?)</b>'\n",
    "        matches = list(set(re.findall(pattern, html)))      \n",
    "        countries_dict = {key:value for (value, key) in matches}\n",
    "        countries = sorted(countries_dict.keys())\n",
    "        return countries, countries_dict\n",
    "    except Exception, e:\n",
    "        print e\n",
    " \n",
    " \n",
    "def get_season_from_csv_url(csv_url):\n",
    "    \"\"\"\n",
    "    Extract season string from csv url\n",
    "    and return apropriate season.\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_url: url\n",
    "             csv file url\n",
    "              \n",
    "    Returns\n",
    "    -------\n",
    "    season: int\n",
    "            Season, ex. 2015\n",
    "    \"\"\"\n",
    "    try:\n",
    "        season_string = re.findall(\"/([0-9]{4})/\", csv_url)[0]\n",
    "        season =  int(season_string[-2:])\n",
    "        if season > 90:\n",
    "            cent = \"19\"\n",
    "        else:\n",
    "            cent = \"20\"\n",
    "        season = cent + season_string[-2:]\n",
    "        return season\n",
    "    except Exception, e:\n",
    "        print e\n",
    " \n",
    "\n",
    "def get_country_csv_urls(country, countries_dict):\n",
    "    \"\"\"\n",
    "    Get csv urls from a country's page.\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    country: string\n",
    "             Name of country\n",
    "              \n",
    "    countries_dict: dictionary\n",
    "                    1-D dictionary containing\n",
    "                    countries name and urls\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    country_csv_urls: list\n",
    "              The csv urls of country page\n",
    "    \"\"\"\n",
    "    country_csv_urls = []\n",
    "    try:\n",
    "        country_url = countries_dict[country]\n",
    "        r = requests.get(country_url)\n",
    "        html = r.text\n",
    "        soup = BeautifulSoup(html)\n",
    "        matches = soup.findAll(\"a\")\n",
    "        for match in matches:\n",
    "            if \"csv\" in match[\"href\"]:\n",
    "                country_csv_url = \"\".join([site, match[\"href\"]])\n",
    "                league = match.text\n",
    "                csv_season = get_season_from_csv_url(match[\"href\"])\n",
    "                csv_details = [country_csv_url, country, league, csv_season]\n",
    "                country_csv_urls.append(csv_details)\n",
    "    except Exception, e:\n",
    "        print e   \n",
    "    return country_csv_urls\n",
    " \n",
    " \n",
    "def folder_preparation(files_folder, countries, csv_urls):\n",
    "    \"\"\"\n",
    "    Create the appropriate folders based on\n",
    "    country names and leagues.\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    files_folder: string\n",
    "                  Filepath of folder\n",
    "                  to save files to\n",
    "     \n",
    "    countries: list\n",
    "               List of countries names\n",
    "     \n",
    "    csv_urls: list\n",
    "              1-D list\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    if not os.path.exists(files_folder):\n",
    "        try:\n",
    "            os.mkdir(files_folder)\n",
    "        except Exception, e:\n",
    "            print e\n",
    "             \n",
    "    for country in countries:\n",
    "        if country not in os.listdir(files_folder):     \n",
    "            try:   \n",
    "                os.mkdir('/'.join([files_folder, country]))\n",
    "            except Exception, e:\n",
    "                print e\n",
    "     \n",
    "    for country in countries:\n",
    "        country_leagues = filter(lambda x: x[1] == country, csv_urls)\n",
    "        for country_league in country_leagues:\n",
    "            country, league = country_league[1:3]\n",
    "            league_folder = '/'.join([files_folder, country, league])\n",
    "            if not os.path.exists(league_folder):\n",
    "                try:\n",
    "                    os.mkdir(league_folder)\n",
    "                except Exception, e:\n",
    "                    print e\n",
    " \n",
    "\n",
    "def download_csv_file(csv_info):\n",
    "    \"\"\"\n",
    "    Download csv file.\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_info: list\n",
    "              1-D list of csv info\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    csv_url, country, league, season = csv_info\n",
    "    league_folders = os.listdir('/'.join([files_folder, country]))\n",
    "    filename = unicode('/'.join([files_folder, country, league, season + '.csv']))\n",
    "    try:\n",
    "        r = requests.get(csv_url, stream=True)\n",
    "        if r.status_code == 200:\n",
    "            with open(filename, 'wb') as f:\n",
    "                for chunk in r.iter_content(1024):\n",
    "                    f.write(chunk)\n",
    "    except Exception, e:\n",
    "        print e\n",
    " \n",
    "\n",
    "def download_multiple_csv_files(csv_urls, amount):\n",
    "    \"\"\"\n",
    "    Download multiple csv files\n",
    "     \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_urls: list\n",
    "              1-D list\n",
    "     \n",
    "    amount: int\n",
    "            how many files to\n",
    "            download at once\n",
    "     \n",
    "    Returns\n",
    "    -------\n",
    "    \"\"\"\n",
    "    pool = workerpool.WorkerPool(size=amount)\n",
    "    pool.map(download_csv_file, csv_urls)\n",
    "    pool.shutdown()\n",
    "    pool.wait()\n",
    "\n",
    "    \n",
    "def correct_csv(csv_file):\n",
    "    with open(csv_file, \"rb\") as f:\n",
    "        csvfile = csv.reader(f)\n",
    "\n",
    "        headers = csvfile.next()\n",
    "        total_headers = len(headers)\n",
    "        new_lines = [headers]\n",
    "        for lines in csvfile:\n",
    "            new_line = lines[:total_headers]\n",
    "            new_lines.append(new_line)\n",
    "\n",
    "    with open(csv_file, \"wb\") as f:\n",
    "        csvfile = csv.writer(f)\n",
    "        csvfile.writerows(new_lines)\n",
    "\n",
    "\n",
    "def process_file(filepath):\n",
    "    \"\"\"\n",
    "    Process file and add to dataframe.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    filepath: string\n",
    "              \n",
    "    \n",
    "    Returns\n",
    "    ------- \n",
    "    df_file: dataframe\n",
    "    \"\"\"\n",
    "    \n",
    "    season = int(filepath.split('\\\\')[-1].split('.')[0])\n",
    "    country = filepath.split('\\\\')[-3]\n",
    "    league = filepath.split('\\\\')[-2]\n",
    "    try:\n",
    "        df_file = pd.read_csv(filepath, sep= \",\", na_values=[\"\", \" \", \"-\"])\n",
    "    except Exception, e:\n",
    "        correct_csv(filepath) # Lines with more items than expected\n",
    "        df_file = pd.read_csv(filepath, sep= \",\", na_values=[\"\", \" \", \"-\"])\n",
    "    \n",
    "    df_file.dropna(axis=0,how='all', inplace=True) # Drop empty lines\n",
    "    df_file.dropna(axis=1, how=\"all\", inplace=True) # Drop all empty columns\n",
    "    df_file.dropna(axis=1, thresh = 0.5 * df_file.shape[0], inplace=True) # Drop columns with a few items   \n",
    "    df_file[\"Season\"] = season\n",
    "    df_file[\"Country\"] = country\n",
    "    df_file[\"League\"] = league\n",
    "\n",
    "    try:\n",
    "        df_file.rename(columns={\"HT\": \"HomeTeam\", \"AT\": \"AwayTeam\"}, inplace=True) # Rename HT to HomeTeam and AT to AwayTeam\n",
    "    except Exception, e:\n",
    "        print e   \n",
    "    \n",
    "    return df_file\n",
    "\n",
    "\n",
    "def get_ftsc(x):\n",
    "    \"\"\"\n",
    "    Get Full Time Score.\n",
    "    \"\"\"\n",
    "     \n",
    "    fthg, ftag = x[\"FTHG\"], x[\"FTAG\"]\n",
    "    if not np.isnan(fthg) and not np.isnan(ftag):\n",
    "        ftsc = \"-\".join([str(fthg), str(ftag)]).replace(\".0\", \"\")\n",
    "    else:\n",
    "        ftsc = \"-\"\n",
    "    return ftsc\n",
    " \n",
    " \n",
    "def get_htsc(x):\n",
    "    \"\"\"\n",
    "    Get Half Time Score.\n",
    "    \"\"\"\n",
    "     \n",
    "    hthg, htag = x[\"HTHG\"], x[\"HTAG\"]\n",
    "    if not np.isnan(hthg) and not np.isnan(htag):\n",
    "        #if hthg.dtype == float and htag.dtype == float:        \n",
    "        htsc = \"-\".join([str(hthg), str(htag)]).replace(\".0\", \"\")\n",
    "        #else:\n",
    "            #htsc = \"-\"\n",
    "    else:\n",
    "        htsc = \"-\"\n",
    "    return htsc\n",
    " \n",
    " \n",
    "def get_date(x):\n",
    "    \"\"\"\n",
    "    Reformat date.\n",
    "    \"\"\"\n",
    "     \n",
    "    date = x[\"Date\"]\n",
    "    if date:\n",
    "        try:\n",
    "            new_date = datetime.datetime.strftime(datetime.datetime.strptime(date, \"%d/%m/%y\"), \"%d/%m/%Y\")\n",
    "        except:\n",
    "            new_date = date\n",
    "    else:\n",
    "        new_date = \"-\"\n",
    "    return new_date    \n",
    " \n",
    " \n",
    "def total_goals_category(x):\n",
    "    \"\"\"\n",
    "    Get total goals category.\n",
    "    \"\"\"\n",
    "     \n",
    "    total_goals = x[\"Total_Goals\"]\n",
    "    if not np.isnan(total_goals):\n",
    "        if 0 <= total_goals < 2:\n",
    "            total_goals_category = \"0-1\"\n",
    "        elif 2 <= total_goals < 4:\n",
    "            total_goals_category = \"2-3\"\n",
    "        elif 4 <= total_goals < 7:\n",
    "            total_goals_category = \"4-6\"\n",
    "        elif 7 <= total_goals:\n",
    "            total_goals_category = \"7\"\n",
    "        else:\n",
    "            total_goals_category = \"-\"\n",
    "    else:\n",
    "        total_goals_category = \"-\"\n",
    " \n",
    "    return total_goals_category        \n",
    "        \n",
    " \n",
    "#Script\n",
    "site = \"http://www.football-data.co.uk/\"\n",
    "files_folder = \"Files\"\n",
    "  \n",
    "countries, countries_dict = get_country_urls(site)\n",
    "csv_urls = []\n",
    "for country in countries:\n",
    "    country_csv_urls = get_country_csv_urls(country, countries_dict)\n",
    "    csv_urls.extend(country_csv_urls)    \n",
    "     \n",
    "folder_preparation(files_folder, countries, csv_urls)\n",
    "download_multiple_csv_files(csv_urls, 10)\n",
    "\n",
    "football_files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(files_folder):\n",
    "    football_files.extend(map(lambda x: os.path.join(dirpath, x), filenames))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for each_file in football_files:\n",
    "    try:\n",
    "        df_file = process_file(each_file)\n",
    "        df = df.append(df_file, ignore_index=True)\n",
    "    except Exception, e:\n",
    "        print e\n",
    " \n",
    "# Add custom columns\n",
    "df[\"HTSC\"] = df.apply(get_htsc, axis=1) # Fix HTSC\n",
    "df[\"FTSC\"] = df.apply(get_ftsc, axis=1) # Fix FTSC\n",
    "df[\"Date\"] = df.apply(get_date, axis=1) # Fix Date\n",
    " \n",
    "df[\"B365_HA_Odds_Class\"] = (df.B365H / df.B365A).apply(lambda x: round(x, 2))\n",
    "df[\"B365_HD_Odds_Class\"] = (df.B365H / df.B365D).apply(lambda x: round(x, 2))    \n",
    "df[\"B365_AD_Odds_Class\"] = (df.B365A / df.B365D).apply(lambda x: round(x, 2))   \n",
    "df[\"Total_Goals\"] = df.FTHG + df.FTAG\n",
    "df[\"Under_Over\"] = df[\"Total_Goals\"].apply(lambda x: \"O\" if x > 2 else \"U\")\n",
    "df[\"Total_Corners\"] = df.HC + df.AC\n",
    " \n",
    "df[\"Total_Goals_Category\"] = df.apply(total_goals_category, axis=1)\n",
    "df[\"Goal_No_Goal\"] = df.apply(lambda x: \"G\" if x[\"FTHG\"] != 0 and x[\"FTAG\"] != 0 else \"NG\", axis=1)\n",
    " \n",
    "# Rearrange columns\n",
    "proper_columns_order = ['Season', 'Country', 'League', 'Div', 'Date',\n",
    "                        'HomeTeam', 'AwayTeam', 'FTSC', 'FTR', 'FTHG',\n",
    "                        'FTAG', 'HTSC', 'HTR', 'HTHG', 'HTAG', 'Under_Over', \n",
    "                        'Goal_No_Goal', 'Total_Goals', 'Total_Goals_Category', 'Total_Corners',\n",
    "                        'B365_HA_Odds_Class', 'B365_HD_Odds_Class', 'B365_AD_Odds_Class', \n",
    "                        'Attendance', 'Referee', 'HS', 'AS', 'HST', 'AST', 'HHW', 'AHW', \n",
    "                        'HC', 'AC', 'HF', 'AF', 'HO', 'AO',  'HY', 'AY', 'HR', 'AR', 'HBP', \n",
    "                        'ABP', 'B365H', 'B365D', 'B365A']\n",
    " \n",
    "other_columns = [i for i in df.columns if i not in proper_columns_order]\n",
    "df = df[proper_columns_order + other_columns]\n",
    "df.fillna(\"-\", inplace=True)\n",
    " \n",
    "# Save to file\n",
    "df.to_csv(os.path.join(files_folder, \"Football-Data.csv\"), index=False)\n",
    "df.to_excel(os.path.join(files_folder, \"Football-Data.xlsx\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
